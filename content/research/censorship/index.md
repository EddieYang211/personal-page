---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Censorship of Online Encyclopedias: Implications for NLP Models"
subtitle: ''
summary: ''
authors:
- admin
- Margaret E. Roberts
tags: []
categories: []
date: '2013-01-01'
lastmod: 2020-08-29T14:26:43+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
publishDate: "2021-03-01T00:00:00Z"
publication_types:
- 1
abstract: 'While artificial intelligence provides the backbone for many tools people use around the world, recent work has brought to attention that the algorithms powering AI are not free of politics, stereotypes, and bias. While most work in this area has focused on the ways in which AI can exacerbate existing inequalities and discrimination, very little work has studied how governments actively shape training data. We describe how censorship has affected the development of Wikipedia corpuses, text data which are regularly used for pre-trained inputs into NLP algorithms. We show that word embeddings trained on Baidu Baike, an online Chinese encyclopedia, have very different associations between adjectives and a range of concepts about democracy, freedom, collective action, equality, and people and historical events in China than its regularly blocked but uncensored counterpart - Chinese language Wikipedia. We examine the implications of these discrepancies by studying their use in downstream AI applications. Our paper shows how government repression, censorship, and self-censorship may impact training data and the applications that draw from them.'
publication: '*Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency*'
doi: 10.1145/3442188.3445916

links:
  - name: PDF
    url: 'https://doi.org/10.1145/3442188.3445916'
---